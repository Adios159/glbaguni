#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬
"""

import asyncio
import logging
import time
import traceback
from typing import Any, Dict, Optional

import httpx


class ApplicationState:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        # ì»´í¬ë„ŒíŠ¸ë“¤
        self.http_client: Optional[httpx.AsyncClient] = None
        self.news_aggregator = None
        self.fetcher = None
        self.summarizer = None
        self.notifier = None
        self.history_service = None

        # ìƒíƒœ ì •ë³´
        self.initialized = False
        self.start_time = None
        self.request_count = 0

    async def initialize(self, importer) -> None:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            self.start_time = time.time()
            logger = logging.getLogger("glbaguni")
            logger.info("ğŸ”§ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘...")

            # HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            await self._init_http_client()

            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            await self._init_database(importer)

            # ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            await self._init_services(importer)

            elapsed = time.time() - self.start_time
            self.initialized = True
            logger.info(f"ğŸ‰ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì™„ë£Œ! ({elapsed:.2f}ì´ˆ)")

        except Exception as e:
            logger = logging.getLogger("glbaguni")
            logger.error(f"âŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error(traceback.format_exc())
            raise

    async def _init_http_client(self) -> None:
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            self.http_client = httpx.AsyncClient(
                timeout=httpx.Timeout(30.0),
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10),
                headers={"User-Agent": "Glbaguni/2.2.0"},
            )
            logger = logging.getLogger("glbaguni")
            logger.info("âœ… HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger = logging.getLogger("glbaguni")
            logger.error(f"HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def _init_database(self, importer) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            init_db_func = importer.services["init_database"]
            # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            await asyncio.to_thread(init_db_func)
            logger = logging.getLogger("glbaguni")
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger = logging.getLogger("glbaguni")
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def _init_services(self, importer) -> None:
        """ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”"""
        try:
            logger = logging.getLogger("glbaguni")
            
            # í•„ìˆ˜ ì„œë¹„ìŠ¤ë“¤
            self.fetcher = importer.services["ArticleFetcher"]()
            self.summarizer = importer.services["ArticleSummarizer"]()
            self.history_service = importer.services["HistoryService"]()

            # ë‰´ìŠ¤ ì• ê·¸ë¦¬ê²Œì´í„° (API í‚¤ í•„ìš”)
            openai_key = importer.services["settings"].OPENAI_API_KEY
            self.news_aggregator = importer.services["NewsAggregator"](
                openai_api_key=openai_key
            )

            # ì´ë©”ì¼ ë…¸í‹°íŒŒì´ì–´ (ì„ íƒì )
            try:
                self.notifier = importer.services["EmailNotifier"]()
                logger.info("âœ… ì´ë©”ì¼ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ ì´ë©”ì¼ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.notifier = None

            logger.info("âœ… ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger = logging.getLogger("glbaguni")
            logger.error(f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    async def cleanup(self) -> None:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë¦¬"""
        try:
            logger = logging.getLogger("glbaguni")
            logger.info("ğŸ”„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë¦¬ ì¤‘...")

            if self.http_client:
                await self.http_client.aclose()
                logger.info("âœ… HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì™„ë£Œ")

            self.initialized = False
            logger.info("âœ… ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            logger = logging.getLogger("glbaguni")
            logger.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def increment_request_count(self):
        """ìš”ì²­ ì¹´ìš´íŠ¸ ì¦ê°€"""
        self.request_count += 1

    def get_stats(self) -> Dict[str, Any]:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ í†µê³„ ë°˜í™˜"""
        return {
            "initialized": self.initialized,
            "uptime_seconds": time.time() - self.start_time if self.start_time else 0,
            "request_count": self.request_count,
            "components": {
                "http_client": bool(self.http_client),
                "fetcher": bool(self.fetcher),
                "summarizer": bool(self.summarizer),
                "notifier": bool(self.notifier),
                "history_service": bool(self.history_service),
                "news_aggregator": bool(self.news_aggregator),
            },
        } 