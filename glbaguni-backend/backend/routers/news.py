#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
News Router
ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìì—°ì–´ ì²˜ë¦¬ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
"""

import uuid
from datetime import datetime
from typing import List, Optional

from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException
from pydantic import BaseModel
from sqlalchemy.orm import Session

# ì˜ì¡´ì„± ì„í¬íŠ¸
try:
    from database import get_db
    from models import NewsSearchRequest, NewsSearchResponse
    from services.gpt_service import GPTService
    from services.news_service import NewsService
    from utils.validator import validate_user_input
except ImportError:
    try:
        from backend.database import get_db
        from backend.models import NewsSearchRequest, NewsSearchResponse
        from backend.services.gpt_service import GPTService
        from backend.services.news_service import NewsService
        from backend.utils.validator import validate_user_input
    except ImportError:
        # ê¸°ë³¸ê°’ìœ¼ë¡œ None ë˜ëŠ” Mock ê°ì²´ ì‚¬ìš©
        get_db = None
        NewsSearchRequest = None
        NewsSearchResponse = None
        GPTService = None
        NewsService = None
        def validate_user_input(text: str, max_length: int = 5000) -> str:
            return text

import logging

logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/news", tags=["news"])


# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class SearchQueryRequest(BaseModel):
    """ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬ ìš”ì²­"""

    query: str
    max_articles: int = 10
    language: str = "ko"
    user_id: Optional[str] = None


class KeywordExtractionRequest(BaseModel):
    """í‚¤ì›Œë“œ ì¶”ì¶œ ìš”ì²­"""

    text: str
    max_keywords: int = 10


# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì•ˆì „í•œ ì´ˆê¸°í™”)
try:
    news_service = NewsService() if NewsService else None
except Exception:
    news_service = None


@router.post("/search")
async def search_news(
    request: SearchQueryRequest,
    background_tasks: BackgroundTasks,
):
    """
    ìì—°ì–´ ì¿¼ë¦¬ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    - **query**: ê²€ìƒ‰í•  ë‰´ìŠ¤ ì£¼ì œ (ì˜ˆ: "ìš”ì¦˜ ë°˜ë„ì²´ ë‰´ìŠ¤ ì•Œë ¤ì¤˜")
    - **max_articles**: ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ê°’: 10)
    - **language**: ìš”ì•½ ì–¸ì–´ (ko/en)
    - **user_id**: ì‚¬ìš©ì ID (ì„ íƒì‚¬í•­)
    """
    request_id = str(uuid.uuid4())[:8]

    try:
        # 1. ìš”ì²­ ìˆ˜ì‹ 
        logger.info(f"ğŸ“¥ [ë‰´ìŠ¤ê²€ìƒ‰] ì‚¬ìš©ì ì…ë ¥ ìˆ˜ì‹  ì™„ë£Œ - ID: {request_id}")
        logger.info(f"ğŸ” [{request_id}] ë‰´ìŠ¤ ê²€ìƒ‰ ìš”ì²­: '{request.query}'")

        # 2. ì…ë ¥ ê²€ì¦ ì‹œì‘
        logger.info(f"ğŸ” [ê²€ì¦] ê²€ìƒ‰ ì¿¼ë¦¬ ê²€ì¦ ì‹œì‘ - ID: {request_id}")

        # ì…ë ¥ ê²€ì¦ (ë§¤ê°œë³€ìˆ˜ ìˆœì„œ ìˆ˜ì •)
        validated_query = validate_user_input(request.query, 1000)

        if len(validated_query.strip()) < 2:
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")

        # 2. ì…ë ¥ ê²€ì¦ ì™„ë£Œ
        logger.info(f"ğŸ” [ê²€ì¦] ê²€ìƒ‰ ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ - ID: {request_id}")

        # 3. ì²˜ë¦¬ ì‹œì‘
        logger.info(f"âš™ï¸ [ì²˜ë¦¬] ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰ ì‹œì‘ - ID: {request_id}")

        # ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰ (ì‹¤ì œ ë©”ì„œë“œ ì‚¬ìš©)
        if news_service:
            search_result = await news_service.search_news(
                query=validated_query,
                max_results=request.max_articles,
                sources=None
            )
        else:
            search_result = []

        # 4. ì²˜ë¦¬ ì™„ë£Œ
        logger.info(f"âœ… [ì™„ë£Œ] ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ - ID: {request_id}: {len(search_result)}ê°œ ê¸°ì‚¬")

        # 5. ì‘ë‹µ ì „ì†¡
        logger.info(f"ğŸ“¤ [ì‘ë‹µ] í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µ ì „ì†¡ - ID: {request_id}")

        return {
            "success": True,
            "message": f"{len(search_result)}ê°œì˜ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.",
            "articles": [
                {
                    "title": article.title,
                    "url": str(article.url),
                    "content": article.content[:500] + "..." if len(article.content) > 500 else article.content,
                    "source": article.source,
                    "published_date": article.published_at.isoformat() if article.published_at else None,
                }
                for article in search_result
            ],
            "extracted_keywords": [],  # í‚¤ì›Œë“œ ì¶”ì¶œì€ ë³„ë„ êµ¬í˜„ í•„ìš”
            "total_articles": len(search_result),
            "request_id": request_id,
            "processed_at": datetime.now().isoformat(),
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ì˜¤ë¥˜] ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - ID: {request_id}: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.post("/extract-keywords")
async def extract_keywords(request: KeywordExtractionRequest):
    """
    í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    - **text**: í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸
    - **max_keywords**: ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜
    """
    request_id = str(uuid.uuid4())[:8]

    try:
        # 1. ìš”ì²­ ìˆ˜ì‹ 
        logger.info(f"ğŸ“¥ [í‚¤ì›Œë“œì¶”ì¶œ] ì‚¬ìš©ì ì…ë ¥ ìˆ˜ì‹  ì™„ë£Œ - ID: {request_id}")
        logger.info(f"ğŸ·ï¸ [{request_id}] í‚¤ì›Œë“œ ì¶”ì¶œ ìš”ì²­")

        # 2. ì…ë ¥ ê²€ì¦ ì‹œì‘
        logger.info(f"ğŸ” [ê²€ì¦] í…ìŠ¤íŠ¸ ê²€ì¦ ì‹œì‘ - ID: {request_id}")

        # ì…ë ¥ ê²€ì¦ (ë§¤ê°œë³€ìˆ˜ ìˆœì„œ ìˆ˜ì •)
        validated_text = validate_user_input(request.text, 10000)

        # 2. ì…ë ¥ ê²€ì¦ ì™„ë£Œ
        logger.info(f"ğŸ” [ê²€ì¦] í…ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ - ID: {request_id}")

        # 3. ì²˜ë¦¬ ì‹œì‘
        logger.info(f"âš™ï¸ [ì²˜ë¦¬] í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰ ì‹œì‘ - ID: {request_id}")

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” NLP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
        import re
        words = re.findall(r'\b\w+\b', validated_text)
        keywords = list(set(word for word in words if len(word) > 2))[:request.max_keywords]

        # 4. ì²˜ë¦¬ ì™„ë£Œ
        logger.info(f"âœ… [ì™„ë£Œ] í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ - ID: {request_id}: {len(keywords)}ê°œ")

        # 5. ì‘ë‹µ ì „ì†¡
        logger.info(f"ğŸ“¤ [ì‘ë‹µ] í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µ ì „ì†¡ - ID: {request_id}")

        return {
            "success": True,
            "keywords": keywords,
            "count": len(keywords),
            "request_id": request_id,
            "processed_at": datetime.now().isoformat(),
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [ì˜¤ë¥˜] í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - ID: {request_id}: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/trending")
async def get_trending_news(category: Optional[str] = None, limit: int = 20):
    """
    íŠ¸ë Œë”© ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    - **category**: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒì‚¬í•­)
    - **limit**: ìµœëŒ€ ê¸°ì‚¬ ìˆ˜
    """
    try:
        # ì„ì‹œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” íŠ¸ë Œë”© ë‰´ìŠ¤ API ì‚¬ìš©
        trending_news = []

        return {
            "success": True,
            "trending_news": trending_news,
            "count": len(trending_news),
            "category": category or "all",
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"íŠ¸ë Œë”© ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500, detail=f"íŠ¸ë Œë”© ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/sources")
async def get_news_sources():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë‰´ìŠ¤ ì†ŒìŠ¤ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # ê¸°ë³¸ ë‰´ìŠ¤ ì†ŒìŠ¤ ëª©ë¡
        sources = [
            {"name": "ë„¤ì´ë²„ ë‰´ìŠ¤", "type": "portal", "language": "ko"},
            {"name": "ë‹¤ìŒ ë‰´ìŠ¤", "type": "portal", "language": "ko"},
            {"name": "ì—°í•©ë‰´ìŠ¤", "type": "agency", "language": "ko"},
            {"name": "KBS", "type": "broadcast", "language": "ko"},
            {"name": "MBC", "type": "broadcast", "language": "ko"},
        ]

        return {
            "success": True,
            "sources": sources,
            "count": len(sources),
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ì†ŒìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500, detail="ë‰´ìŠ¤ ì†ŒìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )


@router.get("/health")
async def news_health_check():
    """ë‰´ìŠ¤ ë¼ìš°í„° í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "router": "news",
        "timestamp": datetime.now().isoformat(),
        "news_service_available": news_service is not None,
    }
