#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸€ë°”êµ¬ë‹ˆ ë°±ì—”ë“œ ì„œë²„ v3.0.0 - ì™„ì „ ë¦¬íŒ©í† ë§ ë²„ì „
"""

import os
import sys
import logging
import asyncio
import time
import traceback
from datetime import datetime
from typing import List, Optional, Dict, Any
import uuid
import json
import re
from contextlib import asynccontextmanager

import httpx
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request, Depends, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from sqlalchemy import text
from dotenv import load_dotenv
from pydantic import HttpUrl

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from .models import *
    from .fetcher import ArticleFetcher
    from .summarizer import ArticleSummarizer
    from .notifier import EmailNotifier
    from .config import settings
    from .database import get_db, init_database
    from .history_service import HistoryService
    from .news_aggregator import NewsAggregator
    from .security import validate_input, sanitize_response
    SECURITY_AVAILABLE = True
except ImportError:
    from models import *
    from fetcher import ArticleFetcher
    from summarizer import ArticleSummarizer
    from notifier import EmailNotifier
    from config import settings
    from database import get_db, init_database
    from history_service import HistoryService
    from news_aggregator import NewsAggregator
    try:
        from security import validate_input, sanitize_response
        SECURITY_AVAILABLE = True
    except ImportError:
        SECURITY_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
def setup_logging():
    os.makedirs("logs", exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler("logs/server.log", encoding="utf-8")
        ]
    )
    for logger_name in ["httpx", "httpcore", "urllib3"]:
        logging.getLogger(logger_name).setLevel(logging.WARNING)
    
    logger = logging.getLogger("glbaguni")
    logger.info("ğŸš€ ê¸€ë°”êµ¬ë‹ˆ ì„œë²„ v3.0.0 ì‹œì‘")
    return logger

logger = setup_logging()

# í™˜ê²½ë³€ìˆ˜ ê²€ì¦
def validate_env():
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key or not api_key.startswith('sk-'):
        logger.error("âŒ OPENAI_API_KEY ëˆ„ë½ ë˜ëŠ” ì˜ëª»ëœ í˜•ì‹")
        return False
    logger.info("âœ… í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ì™„ë£Œ")
    return True

if not validate_env():
    sys.exit(1)

# ì „ì—­ ì»´í¬ë„ŒíŠ¸
class Components:
    http_client: Optional[httpx.AsyncClient] = None
    fetcher: Optional[ArticleFetcher] = None
    summarizer: Optional[ArticleSummarizer] = None
    notifier: Optional[EmailNotifier] = None
    history_service: Optional[HistoryService] = None
    news_aggregator: Optional[NewsAggregator] = None

comp = Components()

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
async def safe_call(func, *args, **kwargs):
    """ì•ˆì „í•œ í•¨ìˆ˜ í˜¸ì¶œ"""
    try:
        if asyncio.iscoroutinefunction(func):
            return await func(*args, **kwargs)
        else:
            return await asyncio.to_thread(func, *args, **kwargs)
    except Exception as e:
        logger.error(f"í•¨ìˆ˜ í˜¸ì¶œ ì‹¤íŒ¨: {func.__name__} - {str(e)}")
        raise

def validate_input_text(text: str, max_len: int = 5000) -> str:
    """ì…ë ¥ í…ìŠ¤íŠ¸ ê²€ì¦"""
    if not text or not text.strip():
        raise HTTPException(400, "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    text = text.strip()
    if len(text) > max_len:
        raise HTTPException(400, f"í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ {max_len}ì)")
    
    # XSS ë°©ì§€
    dangerous = [r'<script', r'javascript:', r'on\w+\s*=']
    for pattern in dangerous:
        if re.search(pattern, text, re.IGNORECASE):
            raise HTTPException(400, "ìœ„í—˜í•œ ë¬¸ì íŒ¨í„´ ê°ì§€")
    
    return text

def error_response(code: str, msg: str, status: int = 500) -> Dict:
    """í‘œì¤€ ì—ëŸ¬ ì‘ë‹µ"""
    return {
        "success": False,
        "error_code": code,
        "message": msg,
        "timestamp": datetime.now().isoformat(),
        "request_id": str(uuid.uuid4())[:8]
    }

# ì•± ë¼ì´í”„ì‚¬ì´í´
@asynccontextmanager
async def lifespan(app: FastAPI):
    start_time = time.time()
    
    try:
        logger.info("ğŸ”§ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”...")
        
        # HTTP í´ë¼ì´ì–¸íŠ¸
        comp.http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0),
            limits=httpx.Limits(max_connections=20)
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤
        await safe_call(init_database)
        
        # ì»´í¬ë„ŒíŠ¸ë“¤
        comp.fetcher = ArticleFetcher()
        comp.summarizer = ArticleSummarizer()
        comp.history_service = HistoryService()
        comp.news_aggregator = NewsAggregator(openai_api_key=settings.OPENAI_API_KEY)
        
        try:
            comp.notifier = EmailNotifier()
            logger.info("âœ… ì´ë©”ì¼ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        except Exception as e:
            logger.warning(f"âš ï¸ ì´ë©”ì¼ ì„œë¹„ìŠ¤ ì‹¤íŒ¨: {e}")
            comp.notifier = None
        
        elapsed = time.time() - start_time
        logger.info(f"ğŸ‰ ì´ˆê¸°í™” ì™„ë£Œ! ({elapsed:.2f}ì´ˆ)")
        
        yield
        
    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise
    finally:
        logger.info("ğŸ”„ ì„œë²„ ì¢…ë£Œ...")
        if comp.http_client:
            await comp.http_client.aclose()

# FastAPI ì•±
app = FastAPI(
    title="ê¸€ë°”êµ¬ë‹ˆ RSS ìš”ì•½ ì„œë¹„ìŠ¤",
    version="3.0.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start = time.time()
    req_id = str(uuid.uuid4())[:8]
    
    client = request.client.host if request.client else "unknown"
    logger.info(f"ğŸ“¥ [{req_id}] {request.method} {request.url.path} from {client}")
    
    try:
        response = await call_next(request)
        elapsed = time.time() - start
        logger.info(f"ğŸ“¤ [{req_id}] {response.status_code} in {elapsed:.3f}s")
        return response
    except Exception as e:
        elapsed = time.time() - start
        logger.error(f"ğŸ’¥ [{req_id}] Error in {elapsed:.3f}s: {e}")
        raise

# ì˜ˆì™¸ í•¸ë“¤ëŸ¬
@app.exception_handler(HTTPException)
async def http_error_handler(request: Request, exc: HTTPException):
    logger.error(f"HTTP {exc.status_code}: {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content=error_response(f"HTTP_{exc.status_code}", exc.detail, exc.status_code)
    )

@app.exception_handler(Exception)
async def global_error_handler(request: Request, exc: Exception):
    error_id = str(uuid.uuid4())[:8]
    logger.error(f"ğŸ’¥ Unexpected error [{error_id}]: {exc}")
    logger.error(traceback.format_exc())
    
    return JSONResponse(
        status_code=500,
        content=error_response(
            "INTERNAL_ERROR",
            "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            500
        )
    )

# API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/")
async def root():
    return {
        "service": "ê¸€ë°”êµ¬ë‹ˆ RSS ìš”ì•½ ì„œë¹„ìŠ¤",
        "version": "3.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health():
    start = time.time()
    status = {"status": "healthy", "timestamp": datetime.now().isoformat()}
    checks = {}
    
    try:
        # í™˜ê²½ë³€ìˆ˜
        checks["env"] = {
            "openai": "âœ…" if os.getenv("OPENAI_API_KEY") else "âŒ",
            "smtp": "âœ…" if os.getenv("SMTP_USERNAME") else "âš ï¸"
        }
        
        # ë°ì´í„°ë² ì´ìŠ¤
        try:
            db = next(get_db())
            await asyncio.to_thread(db.execute, text("SELECT 1"))
            db.close()
            checks["database"] = "âœ…"
        except Exception:
            checks["database"] = "âŒ"
            status["status"] = "degraded"
        
        # ì»´í¬ë„ŒíŠ¸
        checks["components"] = {
            "fetcher": "âœ…" if comp.fetcher else "âŒ",
            "summarizer": "âœ…" if comp.summarizer else "âŒ",
            "notifier": "âœ…" if comp.notifier else "âš ï¸"
        }
        
        status["checks"] = checks
        status["response_time_ms"] = round((time.time() - start) * 1000, 2)
        
        return status
    except Exception as e:
        return {"status": "error", "error": str(e)}

@app.get("/debug")
async def debug():
    return {
        "env": {
            "OPENAI_API_KEY": "SET" if os.getenv("OPENAI_API_KEY") else "NOT_SET",
            "SMTP_USERNAME": "SET" if os.getenv("SMTP_USERNAME") else "NOT_SET"
        },
        "components": {
            "http_client": bool(comp.http_client),
            "fetcher": bool(comp.fetcher),
            "summarizer": bool(comp.summarizer),
            "notifier": bool(comp.notifier)
        },
        "security": SECURITY_AVAILABLE,
        "timestamp": datetime.now().isoformat()
    }

@app.post("/summarize")
async def summarize_articles(request: SummaryRequest, bg: BackgroundTasks, db: Session = Depends(get_db)):
    req_id = str(uuid.uuid4())[:8]
    logger.info(f"ğŸš€ [{req_id}] ìš”ì•½ ìš”ì²­ ì‹œì‘")
    
    try:
        if not request.rss_urls and not request.article_urls:
            raise HTTPException(400, "RSS URL ë˜ëŠ” ê¸°ì‚¬ URLì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        user_id = request.user_id or str(uuid.uuid4())
        max_articles = min(request.max_articles or 10, 20)
        
        rss_urls = [str(url) for url in (request.rss_urls or [])[:10]]
        article_urls = [str(url) for url in (request.article_urls or [])[:15]]
        
        logger.info(f"ğŸ“Š [{req_id}] RSS: {len(rss_urls)}, ê¸°ì‚¬: {len(article_urls)}")
        
        # ê¸°ì‚¬ ìˆ˜ì§‘
        if not comp.fetcher:
            raise HTTPException(500, "ê¸°ì‚¬ ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ì—†ìŒ")
        
        articles = await safe_call(
            comp.fetcher.fetch_multiple_sources,
            rss_urls=rss_urls or None,
            article_urls=article_urls or None,
            max_articles=max_articles
        )
        
        if not articles:
            return SummaryResponse(
                success=False,
                message="ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                total_articles=0,
                processed_at=datetime.now(),
                user_id=user_id
            )
        
        logger.info(f"âœ… [{req_id}] {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
        
        # ìš”ì•½ ì²˜ë¦¬
        summaries = []
        for i, article in enumerate(articles, 1):
            try:
                logger.info(f"ğŸ“ [{req_id}] ìš”ì•½ {i}/{len(articles)}")
                
                summary_result = await safe_call(
                    comp.summarizer.summarize,
                    f"ì œëª©: {article.title}\në‚´ìš©: {article.content}",
                    request.language or "ko"
                )
                
                if isinstance(summary_result, dict):
                    summary_text = summary_result.get("summary", "ìš”ì•½ ì‹¤íŒ¨")
                else:
                    summary_text = str(summary_result)
                
                summaries.append(ArticleSummary(
                    title=article.title,
                    url=str(article.url),
                    summary=summary_text,
                    source=getattr(article, 'source', 'unknown'),
                    original_length=len(article.content),
                    summary_length=len(summary_text)
                ))
                
            except Exception as e:
                logger.error(f"âŒ [{req_id}] ìš”ì•½ ì‹¤íŒ¨: {e}")
                continue
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
        if request.recipient_email and summaries and comp.notifier:
            bg.add_task(send_email_bg, request.recipient_email, summaries, req_id)
        
        if summaries and comp.history_service:
            bg.add_task(save_history_bg, user_id, summaries, db, req_id)
        
        logger.info(f"ğŸ‰ [{req_id}] ìš”ì•½ ì™„ë£Œ: {len(summaries)}ê°œ")
        
        return SummaryResponse(
            success=True,
            message=f"{len(summaries)}ê°œ ê¸°ì‚¬ ìš”ì•½ ì™„ë£Œ",
            summaries=summaries,
            total_articles=len(summaries),
            processed_at=datetime.now(),
            user_id=user_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ’¥ [{req_id}] ìš”ì•½ ì˜¤ë¥˜: {e}")
        raise HTTPException(500, f"ìš”ì•½ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

@app.post("/summarize-text")
async def summarize_text(request: Request):
    req_id = str(uuid.uuid4())[:8]
    
    try:
        body = await request.json()
        text = body.get("text", "")
        language = body.get("language", "ko")
        
        validated_text = validate_input_text(text, 10000)
        logger.info(f"ğŸ“ [{req_id}] í…ìŠ¤íŠ¸ ìš”ì•½: {len(validated_text)}ì")
        
        if not comp.summarizer:
            raise HTTPException(500, "ìš”ì•½ ì„œë¹„ìŠ¤ ì—†ìŒ")
        
        result = await safe_call(comp.summarizer.summarize, validated_text, language)
        
        if isinstance(result, dict):
            summary = result.get("summary", "ìš”ì•½ ì‹¤íŒ¨")
        else:
            summary = str(result)
        
        return {
            "success": True,
            "summary": summary,
            "original_length": len(validated_text),
            "summary_length": len(summary),
            "language": language,
            "processed_at": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ’¥ [{req_id}] í…ìŠ¤íŠ¸ ìš”ì•½ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"í…ìŠ¤íŠ¸ ìš”ì•½ ì‹¤íŒ¨: {e}")

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ë“¤
async def send_email_bg(email: str, summaries: List[ArticleSummary], req_id: str):
    try:
        logger.info(f"ğŸ“§ [{req_id}] ì´ë©”ì¼ ë°œì†¡: {email}")
        if comp.notifier:
            await safe_call(comp.notifier.send_summary_email, email, summaries)
            logger.info(f"âœ… [{req_id}] ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ [{req_id}] ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

async def save_history_bg(user_id: str, summaries: List[ArticleSummary], db: Session, req_id: str):
    try:
        logger.info(f"ğŸ’¾ [{req_id}] íˆìŠ¤í† ë¦¬ ì €ì¥: {len(summaries)}ê°œ")
        
        if comp.history_service:
            for summary in summaries:
                try:
                    url = HttpUrl(summary.url) if isinstance(summary.url, str) else summary.url
                except:
                    url = HttpUrl("https://example.com")
                
                article = Article(
                    title=summary.title,
                    url=url,
                    content=f"ìš”ì•½: {summary.summary}",
                    source=summary.source
                )
                
                await safe_call(
                    comp.history_service.save_summary_history,
                    db, user_id, article, summary.summary, "ko",
                    summary.original_length, summary.summary_length
                )
            
            logger.info(f"âœ… [{req_id}] íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ [{req_id}] íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")

@app.get("/history")
async def get_history(
    user_id: str = Query(..., description="ì‚¬ìš©ì ID"),
    page: int = Query(1, ge=1, description="í˜ì´ì§€ ë²ˆí˜¸"),
    per_page: int = Query(20, ge=1, le=100, description="í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜"),
    language: Optional[str] = Query(None, description="ì–¸ì–´ í•„í„°"),
    db: Session = Depends(get_db)
):
    """ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    req_id = str(uuid.uuid4())[:8]
    
    try:
        logger.info(f"ğŸ“š [{req_id}] íˆìŠ¤í† ë¦¬ ì¡°íšŒ: {user_id}, í˜ì´ì§€ {page}")
        
        if not comp.history_service:
            raise HTTPException(500, "íˆìŠ¤í† ë¦¬ ì„œë¹„ìŠ¤ ì—†ìŒ")
        
        # íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        result = await safe_call(
            comp.history_service.get_user_history,
            db, user_id, page, per_page, language
        )
        
        if not isinstance(result, tuple) or len(result) != 2:
            raise Exception("íˆìŠ¤í† ë¦¬ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
        
        items, total = result
        
        # HistoryItem ë³€í™˜
        history_items = []
        for item in items:
            try:
                keywords = json.loads(item.keywords) if item.keywords else []
            except:
                keywords = []
            
            history_items.append({
                "id": item.id,
                "article_title": item.article_title,
                "article_url": item.article_url,
                "article_source": item.article_source,
                "content_excerpt": item.content_excerpt,
                "summary_text": item.summary_text,
                "summary_language": item.summary_language,
                "original_length": item.original_length,
                "summary_length": item.summary_length,
                "keywords": keywords,
                "created_at": item.created_at.isoformat() if item.created_at else None
            })
        
        logger.info(f"âœ… [{req_id}] íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì™„ë£Œ: {len(history_items)}ê°œ")
        
        return {
            "success": True,
            "history": history_items,
            "total_items": total,
            "page": page,
            "per_page": per_page,
            "total_pages": (total + per_page - 1) // per_page
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ’¥ [{req_id}] íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")

@app.post("/news-search")
async def news_search(request: Request, bg: BackgroundTasks):
    """ë‰´ìŠ¤ ê²€ìƒ‰"""
    req_id = str(uuid.uuid4())[:8]
    
    try:
        body = await request.json()
        query = body.get("query", "")
        max_articles = body.get("max_articles", 10)
        recipient_email = body.get("recipient_email")
        
        query = validate_input_text(query, 500)
        logger.info(f"ğŸ” [{req_id}] ë‰´ìŠ¤ ê²€ìƒ‰: {query}")
        
        if not comp.news_aggregator:
            raise HTTPException(500, "ë‰´ìŠ¤ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì—†ìŒ")
        
        # ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰
        result = await safe_call(
            comp.news_aggregator.process_news_query,
            query,
            min(max_articles, 20)
        )
        
        # ê²°ê³¼ ì²˜ë¦¬
        if isinstance(result, tuple) and len(result) == 2:
            articles, keywords = result
        else:
            articles = result if isinstance(result, list) else []
            keywords = []
        
        logger.info(f"âœ… [{req_id}] ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(articles)}ê°œ")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì´ë©”ì¼ ë°œì†¡
        if recipient_email and articles and comp.notifier:
            bg.add_task(send_news_email_bg, recipient_email, query, articles, req_id)
        
        return {
            "success": True,
            "message": f"{len(articles)}ê°œ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤",
            "articles": [
                {
                    "title": article.title,
                    "url": str(article.url),
                    "summary": getattr(article, 'summary', ''),
                    "source": getattr(article, 'source', 'unknown'),
                    "published_date": article.published_date.isoformat() if getattr(article, 'published_date', None) else None
                }
                for article in articles
            ],
            "total_articles": len(articles),
            "keywords": keywords,
            "processed_at": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ’¥ [{req_id}] ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

@app.get("/recommendations")
async def get_recommendations(
    user_id: str = Query(..., description="ì‚¬ìš©ì ID"),
    limit: int = Query(5, ge=1, le=20, description="ì¶”ì²œ ê°œìˆ˜"),
    db: Session = Depends(get_db)
):
    """ê°œì¸í™” ì¶”ì²œ"""
    req_id = str(uuid.uuid4())[:8]
    
    try:
        logger.info(f"ğŸ’¡ [{req_id}] ì¶”ì²œ ìš”ì²­: {user_id}")
        
        if not comp.history_service:
            raise HTTPException(500, "ì¶”ì²œ ì„œë¹„ìŠ¤ ì—†ìŒ")
        
        # ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì¶”ì²œ
        recommendations = await safe_call(
            comp.history_service.generate_recommendations,
            db, user_id, limit
        )
        
        if not recommendations:
            recommendations = []
        
        logger.info(f"âœ… [{req_id}] ì¶”ì²œ ì™„ë£Œ: {len(recommendations)}ê°œ")
        
        return {
            "success": True,
            "recommendations": [
                {
                    "title": rec.title,
                    "description": rec.description,
                    "url": str(rec.url),
                    "category": rec.category,
                    "confidence_score": rec.confidence_score
                }
                for rec in recommendations
            ],
            "total_recommendations": len(recommendations),
            "user_id": user_id
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ’¥ [{req_id}] ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"ì¶”ì²œ ì‹¤íŒ¨: {e}")

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¶”ê°€
async def send_news_email_bg(email: str, query: str, articles: List, req_id: str):
    try:
        logger.info(f"ğŸ“§ [{req_id}] ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì´ë©”ì¼: {email}")
        
        if comp.notifier:
            # ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ArticleSummary í˜•íƒœë¡œ ë³€í™˜
            summaries = []
            for article in articles[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                summaries.append(ArticleSummary(
                    title=article.title,
                    url=str(article.url),
                    summary=f"'{query}' ê²€ìƒ‰ ê²°ê³¼",
                    source=getattr(article, 'source', 'unknown'),
                    original_length=0,
                    summary_length=0
                ))
            
            await safe_call(comp.notifier.send_summary_email, email, summaries)
            logger.info(f"âœ… [{req_id}] ë‰´ìŠ¤ ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ [{req_id}] ë‰´ìŠ¤ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ ì„œë²„ ì§ì ‘ ì‹¤í–‰")
    uvicorn.run("server_refactored:app", host="0.0.0.0", port=8001, reload=False) 