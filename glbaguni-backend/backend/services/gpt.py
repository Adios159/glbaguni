#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI GPT API ì„œë¹„ìŠ¤ ëª¨ë“ˆ
OpenAI API í˜¸ì¶œê³¼ ì‘ë‹µ ì²˜ë¦¬ë¥¼ ì „ë‹´
"""

import asyncio
import logging
import time
from typing import Any, Dict, List, Optional, Union

import openai

try:
    from ..config.settings import get_settings
    from ..utils.logging_config import get_logger
except ImportError:
    try:
        from ..config import settings
        from ..utils.logging_config import get_logger
    except ImportError:
        import logging

        class MockSettings:
            OPENAI_API_KEY = ""
            OPENAI_MODEL = "gpt-3.5-turbo"

        settings = MockSettings()
        get_logger = logging.getLogger

logger = get_logger("gpt_service")


class GPTService:
    """OpenAI GPT API í˜¸ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        """
        GPT ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            api_key: OpenAI API í‚¤ (ì—†ìœ¼ë©´ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
            model: ì‚¬ìš©í•  ëª¨ë¸ëª… (ì—†ìœ¼ë©´ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´)
        """
        try:
            self.api_key = api_key or get_settings().openai_api_key
            self.model = model or get_settings().openai_model
        except:
            self.api_key = api_key or getattr(settings, "OPENAI_API_KEY", "")
            self.model = model or getattr(settings, "OPENAI_MODEL", "gpt-3.5-turbo")

        if not self.api_key:
            raise ValueError("OpenAI API key is required")

        self.client = openai.OpenAI(api_key=self.api_key)

        # ê¸°ë³¸ ì„¤ì •
        self.default_temperature = 0.5
        self.default_max_tokens = 400
        self.default_timeout = 30

        logger.info(f"GPT Service initialized with model: {self.model}")

    async def safe_gpt_call(
        self, prompt: str, language: str = "ko", max_retries: int = 3
    ) -> str:
        """
        ì•ˆì „í•œ GPT API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

        Args:
            prompt: GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
            language: ì‘ë‹µ ì–¸ì–´ ('ko' ë˜ëŠ” 'en')
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            GPT ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ¤– GPT API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries}")

                # ìš”ì•½ ìƒì„±
                result = await self.generate_summary(prompt, language)

                if result.get("success"):
                    summary = result.get("summary", "")
                    logger.info("âœ… GPT API í˜¸ì¶œ ì„±ê³µ")
                    return summary
                else:
                    error = result.get("error", "Unknown error")
                    logger.warning(f"âš ï¸ GPT API ì˜¤ë¥˜: {error}")

                    if attempt == max_retries - 1:
                        # ë§ˆì§€ë§‰ ì‹œë„ ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ë°˜í™˜
                        return self._generate_fallback_summary(prompt)

            except Exception as e:
                logger.error(f"âŒ GPT API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")

                if attempt == max_retries - 1:
                    logger.error("âŒ ëª¨ë“  GPT API í˜¸ì¶œ ì‹œë„ ì‹¤íŒ¨")
                    return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

                # ì¬ì‹œë„ ì „ ëŒ€ê¸° (ì§€ìˆ˜ ë°±ì˜¤í”„)
                await asyncio.sleep(2**attempt)

        return "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _generate_fallback_summary(self, text: str) -> str:
        """
        GPT API ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ìš”ì•½ ìƒì„±

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸

        Returns:
            ê°„ë‹¨í•œ ìš”ì•½ í…ìŠ¤íŠ¸
        """
        try:
            # ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„í•  ìš”ì•½
            sentences = text.split(".")[:3]
            if sentences:
                result = ". ".join(s.strip() for s in sentences if s.strip()) + "."
                logger.info("âœ… ëŒ€ì•ˆ ìš”ì•½ ìƒì„± ì™„ë£Œ")
                return result
            else:
                return text[:200] + "..." if len(text) > 200 else text
        except Exception:
            return "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def generate_summary(
        self,
        text: str,
        language: str = "ko",
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        custom_prompt: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±

        Args:
            text: ìš”ì•½í•  í…ìŠ¤íŠ¸
            language: ìš”ì•½ ì–¸ì–´ ('ko' ë˜ëŠ” 'en')
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            temperature: ìƒì„± ì˜¨ë„
            custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸

        Returns:
            ìš”ì•½ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # íŒŒë¼ë¯¸í„° ì„¤ì •
            max_tokens = max_tokens or self.default_max_tokens
            temperature = temperature or self.default_temperature

            # ë©”ì‹œì§€ êµ¬ì„±
            messages = self._build_summary_messages(text, language, custom_prompt)

            logger.info(
                f"Generating summary - Language: {language}, Length: {len(text)} chars"
            )

            # API í˜¸ì¶œ
            start_time = time.time()
            response = await self._call_openai_api(
                messages=messages, max_tokens=max_tokens, temperature=temperature
            )
            call_duration = time.time() - start_time

            # ì‘ë‹µ ì²˜ë¦¬
            if not response.choices or not response.choices[0].message.content:
                return {
                    "success": False,
                    "error": "OpenAI API returned no content",
                    "duration": call_duration,
                }

            summary = response.choices[0].message.content.strip()

            result = {
                "success": True,
                "summary": summary,
                "language": language,
                "model": self.model,
                "input_length": len(text),
                "output_length": len(summary),
                "duration": call_duration,
                "tokens_used": response.usage.total_tokens if response.usage else None,
            }

            logger.info(f"Summary generated successfully in {call_duration:.2f}s")
            return result

        except openai.OpenAIError as e:
            logger.error(f"OpenAI API error: {e}")
            return {
                "success": False,
                "error": f"OpenAI API error: {str(e)}",
                "error_type": "openai_error",
            }
        except Exception as e:
            logger.error(f"Unexpected error in summary generation: {e}")
            return {
                "success": False,
                "error": f"Summary generation failed: {str(e)}",
                "error_type": "general_error",
            }

    def _build_summary_messages(
        self, text: str, language: str, custom_prompt: Optional[str] = None
    ) -> List[Dict[str, str]]:
        """ìš”ì•½ì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±"""

        if custom_prompt:
            system_message = custom_prompt
        else:
            if language == "ko":
                system_message = """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ í…ìŠ¤íŠ¸ ìš”ì•½ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
- í•µì‹¬ ë‚´ìš©ì„ ë†“ì¹˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”
- 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”  
- ê°ê´€ì ì´ê³  ì •í™•í•œ ì •ë³´ë§Œ í¬í•¨í•˜ì„¸ìš”"""
            else:
                system_message = """You are a professional text summarization assistant.
Please summarize the given text clearly and concisely in English.
- Make sure not to miss key content
- Summarize in 3-5 sentences
- Include only objective and accurate information"""

        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}"},
        ]

        return messages

    async def _call_openai_api(
        self, messages: List[Dict[str, str]], max_tokens: int, temperature: float
    ) -> Any:
        """OpenAI API ë¹„ë™ê¸° í˜¸ì¶œ"""

        def sync_call():
            return self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                timeout=self.default_timeout,
            )

        return await asyncio.to_thread(sync_call)


# ì „ì—­ GPT ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_gpt_service_instance: Optional[GPTService] = None


def get_gpt_service() -> GPTService:
    """ì „ì—­ GPT ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _gpt_service_instance
    if _gpt_service_instance is None:
        _gpt_service_instance = GPTService()
    return _gpt_service_instance


async def safe_gpt_call(prompt: str, language: str = "ko", max_retries: int = 3) -> str:
    """
    ì „ì—­ safe_gpt_call í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)

    Args:
        prompt: GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
        language: ì‘ë‹µ ì–¸ì–´
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

    Returns:
        GPT ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    try:
        gpt_service = get_gpt_service()
        return await gpt_service.safe_gpt_call(prompt, language, max_retries)
    except Exception as e:
        logger.error(f"Global safe_gpt_call failed: {e}")
        return "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
